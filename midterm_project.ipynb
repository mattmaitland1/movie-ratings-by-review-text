{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Midterm\n",
    "## Team Members:\n",
    "Matthew Maitland, Sofia Beyerlein, Shreeya Indap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "val_data = pd.read_csv('val.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train_data)\n",
    "X_test = pd.DataFrame(test_data)\n",
    "X_dev = pd.DataFrame(val_data)\n",
    "X_train['Phrase'] = train_data['Phrase'].str.lower()\n",
    "X_dev['Phrase'] = val_data['Phrase'].str.lower()\n",
    "X_test['Phrase'] = test_data['Phrase'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna(subset=['Phrase'])\n",
    "X_dev = X_dev.dropna(subset=['Phrase'])\n",
    "\n",
    "# drop rows with NaN \n",
    "X_train = X_train.dropna()\n",
    "X_dev = X_dev.dropna()\n",
    "X_test['Phrase'] = X_test['Phrase'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([wnl.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Phrase'] = X_train['Phrase'].apply(lemmatize_text)\n",
    "X_dev['Phrase'] = X_dev['Phrase'].apply(lemmatize_text)\n",
    "X_test['Phrase'] = X_test['Phrase'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Phrase'] = X_train['Phrase'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "X_dev['Phrase'] = X_dev['Phrase'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "X_test['Phrase'] = X_test['Phrase'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand contractions\n",
    "X_train['Phrase'] = X_train['Phrase'].apply(lambda x: contractions.fix(x))\n",
    "X_dev['Phrase'] = X_dev['Phrase'].apply(lambda x: contractions.fix(x))\n",
    "X_test['Phrase'] = X_test['Phrase'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    From assignment template code\n",
    "    \"\"\"\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', str(text), flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    #added substitutions\n",
    "\n",
    "    #***********added substitutions***********\n",
    "    # remove all the special characters\n",
    "    texter = re.sub(r'\\W', ' ', texter)\n",
    "    # remove all single characters\n",
    "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove single characters from the start\n",
    "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
    "    # Remove numbers\n",
    "    texter = re.sub(r'\\d+', ' ', texter)\n",
    "    # Converting to Lowercase\n",
    "    texter = texter.lower()\n",
    "    # Remove punctuation\n",
    "    texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
    "    # Remove parentheses\n",
    "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
    "    # Remove single quotes\n",
    "    texter = re.sub(r'\\'', ' ', texter)\n",
    "    # Substituting multiple spaces with single space\n",
    "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Phrase'] = X_train['Phrase'].apply(clean)\n",
    "X_dev['Phrase'] = X_dev['Phrase'].apply(clean)\n",
    "X_test['Phrase'] = X_test['Phrase'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into labeled and unlabeled dfs\n",
    "X_train_unlabeled = X_train[X_train['Sentiment']==-100]\n",
    "X_train_labeled = X_train[X_train['Sentiment']!=-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34948 24753\n",
      "59701\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_unlabeled),len(X_train_labeled))\n",
    "print(len(X_train_unlabeled) + len(X_train_labeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Tri-Gram Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF vect w n-grams = 3\n",
    "vectorizer = TfidfVectorizer(max_features=50000, ngram_range=(1, 3))\n",
    "X_train_labeled_vect = vectorizer.fit_transform(X_train_labeled['Phrase'])\n",
    "X_train_unlabeled_vect = vectorizer.transform(X_train_unlabeled['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined_vect = scipy.sparse.vstack([X_train_labeled_vect, X_train_unlabeled_vect])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Before Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=3000, random_state=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logreg on only labeled data\n",
    "clf = LogisticRegression(max_iter=3000, random_state=0, class_weight='balanced')  \n",
    "clf.fit(X_train_labeled_vect, X_train_labeled['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy before Augmentation: 0.9366\n",
      "Validation F1 Score before Augmentation: 0.9365\n"
     ]
    }
   ],
   "source": [
    "# Vectorize \n",
    "X_val_vect = vectorizer.transform(X_dev['Phrase'])\n",
    "y_val = X_dev['Sentiment']\n",
    "\n",
    "# preds\n",
    "y_pred_val = clf.predict(X_val_vect)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "print(f\"Validation Accuracy before Augmentation: {accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score before Augmentation: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM for Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is not needed to validate results, as the final model does not use the GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))  # smaller vectorizer b/c GMM is slow\n",
    "X_train_labeled_vect = vectorizer.fit_transform(X_train_labeled['Phrase'])\n",
    "X_train_unlabeled_vect = vectorizer.transform(X_train_unlabeled['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmaitland/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with GMM Augmented Data: 0.8426\n",
      "Validation F1 Score with GMM Augmented Data: 0.8438\n"
     ]
    }
   ],
   "source": [
    "# fit GMM/get cluster labels for labeled data\n",
    "gmm = GaussianMixture(n_components=5, random_state=0)  \n",
    "gmm.fit(X_train_labeled_vect.toarray())\n",
    "labeled_cluster_assignments = gmm.predict(X_train_labeled_vect.toarray())\n",
    "\n",
    "# map to classes\n",
    "cluster_to_class_mapping = {}\n",
    "for cluster in np.unique(labeled_cluster_assignments):\n",
    "    cluster_indices = np.where(labeled_cluster_assignments == cluster)[0]\n",
    "    common_sentiment = Counter(X_train_labeled.iloc[cluster_indices]['Sentiment']).most_common(1)[0][0]\n",
    "    cluster_to_class_mapping[cluster] = common_sentiment\n",
    "\n",
    "# predict\n",
    "unlabeled_cluster_assignments = gmm.predict(X_train_unlabeled_vect.toarray())\n",
    "\n",
    "# map\n",
    "X_train_unlabeled['Sentiment'] = [cluster_to_class_mapping[cluster] for cluster in unlabeled_cluster_assignments]\n",
    "\n",
    "# Combine w/ originally labeled\n",
    "X_train_augmented = pd.concat([X_train_labeled, X_train_unlabeled])\n",
    "y_train_augmented = X_train_augmented['Sentiment']\n",
    "\n",
    "# refit and evaluate \n",
    "X_train_augmented_vect = vectorizer.transform(X_train_augmented['Phrase'])\n",
    "clf.fit(X_train_augmented_vect, y_train_augmented)\n",
    "X_val_vect = vectorizer.transform(X_dev['Phrase'])\n",
    "y_pred_val = clf.predict(X_val_vect)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "print(f\"Validation Accuracy with GMM Augmented Data: {accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score with GMM Augmented Data: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Multinomial LogReg for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=50000, ngram_range=(1, 3))  # back to big vectorizer\n",
    "X_train_labeled_vect = vectorizer.fit_transform(X_train_labeled['Phrase'])\n",
    "X_train_unlabeled_vect = vectorizer.transform(X_train_unlabeled['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with threshold: 0.99\n",
      "Processing with threshold: 0.98\n",
      "Processing with threshold: 0.97\n",
      "Processing with threshold: 0.96\n",
      "Processing with threshold: 0.95\n",
      "Processing with threshold: 0.9\n",
      "Processing with threshold: 0.85\n",
      "Processing with threshold: 0.8\n",
      "Final number of rows in X_train_augmented: 53374\n"
     ]
    }
   ],
   "source": [
    "thresholds = [.99,.98,.97,.96,.95,.9,.85,.8]\n",
    "\n",
    "# init w/ original labeled data\n",
    "X_train_augmented = X_train_labeled.copy()  \n",
    "\n",
    "# track to prevent duplicates\n",
    "added_indices = set(X_train_augmented.index)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Processing with threshold: {threshold}\")\n",
    "\n",
    "    # retrain on on the current augmented set\n",
    "    X_train_augmented_vect = vectorizer.transform(X_train_augmented['Phrase'])\n",
    "#     X_train_augmented_scaled = scaler.transform(X_train_augmented_vect)\n",
    "    clf.fit(X_train_augmented_vect, X_train_augmented['Sentiment'])\n",
    "\n",
    "    # get preds and probs for unlabeled \n",
    "    y_pred_probs = clf.predict_proba(X_train_unlabeled_vect)\n",
    "    high_confidence_mask = y_pred_probs.max(axis=1) >= threshold\n",
    "    y_pred_high_conf = clf.predict(X_train_unlabeled_vect[high_confidence_mask])\n",
    "\n",
    "    # only select high-confidence rows --> assign predicted labels\n",
    "    X_train_high_conf = X_train_unlabeled.loc[high_confidence_mask].copy()\n",
    "#     print(len(X_train_high_conf))\n",
    "    X_train_high_conf['Sentiment'] = y_pred_high_conf\n",
    "\n",
    "    # filter out duplicates\n",
    "    X_train_high_conf = X_train_high_conf.loc[~X_train_high_conf.index.isin(added_indices)]\n",
    "\n",
    "    # add to set \n",
    "    added_indices.update(X_train_high_conf.index)\n",
    "    \n",
    "    X_train_augmented = pd.concat([X_train_augmented, X_train_high_conf])\n",
    "\n",
    "\n",
    "print(\"Final number of rows in X_train_augmented:\", len(X_train_augmented))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data with high-confidence predictions\n",
    "y_train_augmented = X_train_augmented['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=3000, random_state=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain for evaluation\n",
    "X_train_augmented_vect = vectorizer.transform(X_train_augmented['Phrase'])\n",
    "clf.fit(X_train_augmented_vect, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with Augmented Data: 0.9383\n",
      "Validation F1 Score with Augmented Data: 0.9384\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate on dev set\n",
    "X_val_vect = vectorizer.transform(X_dev['Phrase'])\n",
    "y_val = X_dev['Sentiment']\n",
    "\n",
    "y_pred_val = clf.predict(X_val_vect)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "f1 = f1_score(y_val, y_pred_val, average='weighted')\n",
    "\n",
    "print(f\"Validation Accuracy with Augmented Data: {accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score with Augmented Data: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseID</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseID  Sentiment\n",
       "0         0          3\n",
       "1         1          2\n",
       "2         2          4\n",
       "3         3          1\n",
       "4         4          4"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add X_dev for the final model training\n",
    "X_train_final = pd.concat([X_train_augmented, X_dev])  \n",
    "y_train_final = X_train_final['Sentiment']\n",
    "\n",
    "# vectorize \n",
    "X_train_final_vect = vectorizer.fit_transform(X_train_final['Phrase'])  # refit vectorizer for full data\n",
    "\n",
    "# Train\n",
    "clf.fit(X_train_final_vect, y_train_final)\n",
    "\n",
    "# Predict\n",
    "X_test_vect = vectorizer.transform(X_test['Phrase'])  \n",
    "y_pred_test_final = clf.predict(X_test_vect)\n",
    "\n",
    "submission_test_final = pd.DataFrame({\n",
    "    \"PhraseID\": X_test.index, \n",
    "    \"Sentiment\": y_pred_test_final\n",
    "})\n",
    "submission_test_final.to_csv(\"submission_test_final.csv\", index=False)\n",
    "\n",
    "submission_test_final.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
